---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

See my [Google Scholar](https://scholar.google.com/citations?user=h5OWvc0AAAAJ&hl=en) for more information

- **Stochastic Zeroth-order Riemannian Derivative Estimation and Optimization.** <ins>Jiaxiang Li</ins>, Krishnakumar Balasubramanian, Shiqian Ma. *Mathematics of Operations Research*, 2023 \[[PDF](https://arxiv.org/pdf/2003.11238.pdf)\]

- **Federated Learning on Riemannian Manifolds.** <ins>Jiaxiang Li</ins>, Shiqian Ma. *Appl. Set-Valued Anal. Optim. 5 (2023), 213-232* \[[PDF](https://arxiv.org/pdf/2206.05668.pdf)\]

- **A Riemannian ADMM.** <ins>Jiaxiang Li</ins>, Shiqian Ma, Tejes Srivastava. *Submitted to MOR* (2022) \[[PDF](https://arxiv.org/pdf/2211.02163.pdf)\]

- **Zeroth-order Riemannian Averaging Stochastic Approximation Algorithms.** <ins>Jiaxiang Li</ins>, Krishnakumar Balasubramanian, Shiqian Ma. *SIAM Journal on Optimization (Accepted)* (2024) \[[PDF](https://arxiv.org/pdf/2309.14506.pdf)\]

- **Riemannian Bilevel Optimization.** <ins>Jiaxiang Li</ins>, Shiqian Ma. *Submitted to JMLR* (2024) \[[PDF](https://arxiv.org/pdf/2402.02019.pdf)\]

- **Revisiting zeroth-order optimization for memory-efficient llm fine-tuning: A benchmark.** Yihua Zhang*, Pingzhi Li*, Junyuan Hong*, <ins>Jiaxiang Li</ins>*, Yimeng Zhang, Wenqing Zheng, Pin-Yu Chen et al. *International Conference on Machine Learning* (2024) \[[PDF](https://arxiv.org/pdf/2402.11592)\]

- **Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment.** <ins>Jiaxiang Li</ins>, Siliang Zeng, Hoi-To Wai, Chenliang Li, Alfredo Garcia, Mingyi Hong. (2024) \[[PDF](https://arxiv.org/pdf/2405.17888)\]

- **Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback.** Chenliang Li, Siliang Zeng, Zeyi Liao, <ins>Jiaxiang Li</ins>, Dongyeop Kang, Alfredo Garcia, Mingyi Hong. (2024) \[[PDF](https://arxiv.org/pdf/2406.06874)\]

- **SLTrain: a sparse plus low-rank approach for parameter and memory efficient pretraining.** Andi Han, <ins>Jiaxiang Li</ins>, Wei Huang, Mingyi Hong, Akiko Takeda, Pratik Jawanpuria, Bamdev Mishra. (2024) \[[PDF](https://arxiv.org/pdf/2406.02214)\]

- **Problem-Parameter-Free Decentralized Nonconvex Stochastic Optimization.** <ins>Jiaxiang Li</ins>, Xuxing Chen, Shiqian Ma, Mingyi Hong. (2024) \[[PDF](https://arxiv.org/pdf/2402.08821)\]

